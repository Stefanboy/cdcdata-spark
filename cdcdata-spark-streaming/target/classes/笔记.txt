NoSQL
	Redis,HBase...
		高性能的KV数据库 qbs高达10w
    	K：字符串
    	V：字符串、hash、list、set、sortedset
    	特点：
    		速度快
    		持久化
    		多种数据结构
    		多语言
        多数据库特性
        	总共16个数据库 0-15
        	多数据库之间一般情况下是相互隔离的
下载
	[hadoop@JD sourcecode]$ wget http://download.redis.io/releases/redis-5.0.8.tar.gz
	[hadoop@JD sourcecode]$ tar -zxvf redis-5.0.8.tar.gz -C ../app/
	[hadoop@JD sourcecode]$ cd ../app
	[hadoop@JD app]$ cd redis-5.0.8/
	[hadoop@JD redis-5.0.8]$ make
	[hadoop@JD redis-5.0.8]$ cd src
	[hadoop@JD redis-5.0.8]$ vi redis.conf
	protected-mode no
	port 16379
	tcp-backlog 511
	daemonize yes
	logfile "/home/hadoop/app/redislogs/redis.log"
	[hadoop@JD redis-5.0.8]$ src/redis-server redis.conf
	客户端访问
	[hadoop@JD redis-5.0.8]$ src/redis-cli -p 16379 -h jd
使用
    jd:16379> set name pk
    jd:16379> get name
    jd:16379> exit
    退出服务端
    jd:16379> shutdown
    查看所有的key
    jd:16379> keys *
    选择数据库
    jd:16379> select 1
    再换回默认的数据库
    jd:16379[1]> select 0
    不隔离的命令(清空所有数据库的数据) 生产上该命令要禁用
    jd:16379> flushall

    jd:16379> set user xingxing
    jd:16379> set user2 aaa
    jd:16379> get user
    模糊匹配
    jd:16379> keys user*
    正则匹配
    jd:16379> keys user[0-9]
    判断key是否存在
    jd:16379> exists user
    删除key
    jd:16379> del user
    删除多个key
    jd:16379> del name user
    也可以不进入命令行对redis进行操作
    [hadoop@JD redis-5.0.8]$ src/redis-cli -p 16379 keys "*"
    [hadoop@JD redis-5.0.8]$ src/redis-cli -p 16379 del `user name`

    jd:16379> set user pk
    查看类型
    jd:16379> type user

string(字符串类型)
    set k v
    jd:16379> set ruoze www.xxx.com
    jd:16379> get ruoze
    设置多个k v
    jd:16379> mset ruoze ruozedata1 ruoze2 ruozedata2
    取值
    jd:16379> get ruoze
    取多个值
    jd:16379> mget ruoze ruoze1 ruoze2
    set命令 没有就插入 有就更新
    jd:16379> set ruoze1 ruozedata1.com
    jd:16379> get ruoze1
    setnx命令 该key不存在时 才会做操作
    jd:16379> setnx ruoze1 ruozedata1
    设置一个数值类型
    jd:16379> set money 100
    加1
    jd:16379> incr money
    jd:16379> incr money
    减1
    jd:16379> decr money
    加100
    jd:16379> incrby money 100
    减100
    jd:16379> decrby money 100
    加小数
    jd:16379> incrbyfloat money 11.1
    减小数
    jd:16379> incrbyfloat money -11.1
    查看v的长度
    jd:16379> strlen ruoze

    jd:16379> set msg hello
    从指定位置进行替换
    jd:16379> setrange msg 1 appy
    jd:16379> get msg
    "happy"
    jd:16379> set msg "hello world"
    取0位置到4位置的值
    jd:16379> getrange msg 0 4
    "hello"
    从后面取
    jd:16379> getrange msg -5 -1
    "world"

hash
	一个hash由多个field value pair构成
    设置值
	jd:16379> hset user name ruoze
	jd:16379> hset user age 30
	jd:16379> key *
	取值
	jd:16379> hget user name
	jd:16379> hget user age
	设置多个值
	jd:16379> hmset user age 29 sex male
	拿多个值
	jd:16379> hmget user age sex
	hsetnx只能操作不存在的key
	jd:16379> hsetnx user age 31
	jd:16379> hsetnx user city beijing
	判断key值是否存在
	jd:16379> hexists user city
	//数值增加
	jd:16379> hincrby user age 2
	jd:16379> hlen user
    jd:16379> hkeys user
    jd:16379> hvals user
    jd:16379> hgetall user
    jd:16379> exists user
    jd:16379> hdel user sex

streaming消费语义：http://spark.apache.org/docs/latest/streaming-programming-guide.html#fault-tolerance-semantics

Direct:
SS+Kafka = partitions 1:1 partition

ss对接kafka需要做三件事：
    要去Kafka拿到我们要消费的数据
    offset提交
    处理业务


SS对接kafka：http://spark.apache.org/docs/latest/streaming-kafka-0-10-integration.html
维护offset的三种方式
    Checkpoints
      这种不能用
    Kafka itself
      这种必须要保证幂等性 idempotent：幂等性 即不管你跑多少次，结果都是一样的

offset ==> redis
存入redis的offset的信息包括
    topic partition groupid offset
//redis中是没有事物的 但是有Pipeline操作 该操作可以保证事物 redis集群是没有Pipeline的
存储设计 采用hash结构
    topic_groupid ==> hash key
    partition ==> field
    offset ==> value
问题
    有可能kafka存储周期端 然后streaming挂了后 修复时间慢 等到好了后 redis中存的offset在kafka中已经没有了 怎么办



